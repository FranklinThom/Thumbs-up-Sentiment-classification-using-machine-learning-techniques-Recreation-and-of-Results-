{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SMM Project-final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-CoKelrS_1i"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import model_selection\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZPLwdRUJ-R"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import keras\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Zc6NcQUP4h"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import model_selection\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP5506Y2UZcp",
        "outputId": "8f39bdc7-f4dd-4703-a8f9-05721240ee91"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH9HNS7iS_1i"
      },
      "source": [
        "path_neg = '/content/gdrive/My Drive/txt_sentoken/neg/'\n",
        "\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "negfiles = [f for f in listdir(path_neg) if isfile(join(path_neg, f))]\n",
        "neg=[]\n",
        "for i in negfiles:\n",
        "    neg.append(path_neg+'/'+i)            \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZZesOElS_1i",
        "outputId": "f5a6949f-607a-4564-f820-c0906bd4ea0a"
      },
      "source": [
        "neg[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/txt_sentoken/neg//cv000_29416.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/neg//cv001_19502.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/neg//cv002_17424.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/neg//cv003_12683.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIdsBMOHS_1j",
        "outputId": "110d943d-cc6b-40b4-9dd0-7bd6a8809081"
      },
      "source": [
        "len(negfiles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzYoCs03S_1j"
      },
      "source": [
        "path_pos = '/content/gdrive/My Drive/txt_sentoken/pos/'\n",
        "\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "posfiles = [f for f in listdir(path_pos) if isfile(join(path_pos, f))]\n",
        "pos=[]\n",
        "for i in posfiles:\n",
        "    pos.append(path_pos+'/'+i)\n",
        "    \n",
        "            \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhLRo-kxS_1j",
        "outputId": "c73ea8b6-e1a9-47b4-fb26-6c347b04291b"
      },
      "source": [
        "pos[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/txt_sentoken/pos//cv000_29590.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/pos//cv001_18431.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/pos//cv002_15918.txt',\n",
              " '/content/gdrive/My Drive/txt_sentoken/pos//cv003_11664.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjJ0PLrtS_1k",
        "outputId": "6d2c6717-196a-4b3a-e657-b36d9d5adbda"
      },
      "source": [
        "len(posfiles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hL-ZThOS_1k",
        "outputId": "8972bd18-110f-4d57-d239-379c75019ae3"
      },
      "source": [
        "f = open(pos[0], \"r\")\n",
        "for x in f:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before . \n",
            "\n",
            "for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen . \n",
            "\n",
            "to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd . \n",
            "\n",
            "the book ( or \" graphic novel , \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes . \n",
            "\n",
            "in other words , don't dismiss this film because of its source . \n",
            "\n",
            "if you can get past the whole comic book thing , you might find another stumbling block in from hell's directors , albert and allen hughes . \n",
            "\n",
            "getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that's set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ? \n",
            "\n",
            "the ghetto in question is , of course , whitechapel in 1888 london's east end . \n",
            "\n",
            "it's a filthy , sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision . \n",
            "\n",
            "when the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case . \n",
            "\n",
            "abberline , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium . \n",
            "\n",
            "upon arriving in whitechapel , he befriends an unfortunate named mary kelly ( heather graham , say it isn't so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can't stomach . \n",
            "\n",
            "i don't think anyone needs to be briefed on jack the ripper , so i won't go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay . \n",
            "\n",
            "in the comic , they don't bother cloaking the identity of the ripper , but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end . \n",
            "\n",
            "it's funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts . \n",
            "\n",
            "and from hell's ending had me whistling the stonecutters song from the simpsons for days ( \" who holds back the electric car/who made steve guttenberg a star ? \" ) . \n",
            "\n",
            "don't worry - it'll all make sense when you see it . \n",
            "\n",
            "now onto from hell's appearance : it's certainly dark and bleak enough , and it's surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times , it seems like sleepy hollow 2 ) . \n",
            "\n",
            "the print i saw wasn't completely finished ( both color and music had not been finalized , so no comments about marilyn manson ) , but cinematographer peter deming ( don't say a word ) ably captures the dreariness of victorian-era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black-and-white comic . \n",
            "\n",
            "oscar winner martin childs' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . \n",
            "\n",
            "even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . \n",
            "\n",
            "ians holm ( joe gould's secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . \n",
            "\n",
            "i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn't half bad . \n",
            "\n",
            "the film , however , is all good . \n",
            "\n",
            "2 : 00 - r for strong violence/gore , sexuality , language and drug content \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKTrjdjeS_1m"
      },
      "source": [
        "d={0:[],1:[]}\n",
        "for i in range(len(neg)):\n",
        "    f = open(neg[i], \"r\")\n",
        "    s=''\n",
        "    l=[]\n",
        "    for x in f:\n",
        "        l.append(''.join(x.rstrip('\\n')))\n",
        "    d[0].append(''.join(l))\n",
        "    \n",
        "        \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5bFAiHSS_1n",
        "outputId": "765f1410-849e-463c-d30e-6b1cbc02294f"
      },
      "source": [
        "len(d[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSyXITvTS_1n"
      },
      "source": [
        "for i in range(len(pos)):\n",
        "    f = open(pos[i], \"r\")\n",
        "    s=''\n",
        "    l=[]\n",
        "    for x in f:\n",
        "        l.append(''.join(x.rstrip('\\n')))\n",
        "    d[1].append(''.join(l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSyl0E1TS_1n",
        "outputId": "e132768c-9d36-48f4-b479-1cc4a06039e3"
      },
      "source": [
        "len(d[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Xo2EYHS_1n"
      },
      "source": [
        "df1=pd.DataFrame(d[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yULG-E9S_1n"
      },
      "source": [
        "df1['tar']=[0 for i in range(1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fWm_RbQS_1n"
      },
      "source": [
        "df1.columns=['text','tar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0nABsBALS_1n",
        "outputId": "30736ae2-ecc2-4702-9eaf-05120fc0aa44"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review damn th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  plot : two teen couples go to a church party ,...    0\n",
              "1  the happy bastard's quick movie review damn th...    0\n",
              "2  it is movies like these that make a jaded movi...    0\n",
              "3   \" quest for camelot \" is warner bros . ' firs...    0\n",
              "4  synopsis : a mentally unstable man undergoing ...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj9QhjozS_1o"
      },
      "source": [
        "df2=pd.DataFrame(d[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7TxIWRS_1o"
      },
      "source": [
        "df2['tar']=[1 for i in range(1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE-rr9kQS_1o"
      },
      "source": [
        "df2.columns=['text','tar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "RTHHEpjdS_1o",
        "outputId": "e7979db7-63f7-4f25-dc28-a72f4d299e47"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>films adapted from comic books have had plenty...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>every now and then a movie comes along from a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you've got mail works alot better than it dese...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moviemaking is a lot like being the general ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  films adapted from comic books have had plenty...    1\n",
              "1  every now and then a movie comes along from a ...    1\n",
              "2  you've got mail works alot better than it dese...    1\n",
              "3   \" jaws \" is a rare film that grabs your atten...    1\n",
              "4  moviemaking is a lot like being the general ma...    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sneKwnwoS_1o"
      },
      "source": [
        "df=pd.concat([df1,df2],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9fWS37YLS_1o",
        "outputId": "aaccc7e1-fbf0-4bda-9565-24c07b082e8b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review damn th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  plot : two teen couples go to a church party ,...    0\n",
              "1  the happy bastard's quick movie review damn th...    0\n",
              "2  it is movies like these that make a jaded movi...    0\n",
              "3   \" quest for camelot \" is warner bros . ' firs...    0\n",
              "4  synopsis : a mentally unstable man undergoing ...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T1kd38bS_1o",
        "outputId": "a0cf0065-cee6-4637-9bb8-636bc59e7906"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0Ji2PQD_S_1o",
        "outputId": "4ebe72ba-b035-45d0-d2b8-5e9ac9762c35"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review damn th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  plot : two teen couples go to a church party ,...    0\n",
              "1  the happy bastard's quick movie review damn th...    0\n",
              "2  it is movies like these that make a jaded movi...    0\n",
              "3   \" quest for camelot \" is warner bros . ' firs...    0\n",
              "4  synopsis : a mentally unstable man undergoing ...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jkgzI75S_1p",
        "outputId": "85f0f695-06f4-427e-dfac-b81e77999cba"
      },
      "source": [
        "df['text'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    plot : two teen couples go to a church party ,...\n",
              "0    films adapted from comic books have had plenty...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3pHS9BJS_1p"
      },
      "source": [
        "df=df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4do3jc6S_1p",
        "outputId": "912ca030-8ff6-4ca9-b292-97c3eec0c5f3"
      },
      "source": [
        "counts=[len(df['text'][i].split()) for i in range(2000)]\n",
        "mean=sum(counts)/len(counts)\n",
        "mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "746.3405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLSbiNZnS_1p"
      },
      "source": [
        "df['text'].dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA7iYvOaS_1q",
        "outputId": "b85c4dad-8f07-4c87-8d6b-26aa1c26c305"
      },
      "source": [
        "len(df['text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2a_IxWo2gW"
      },
      "source": [
        "fd=df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKgHsxPNS_1q"
      },
      "source": [
        "df['text'] = [w.lower() for w in df['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4hOnj3mS_1q"
      },
      "source": [
        "##fd=df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE1qmv_fS_1q",
        "outputId": "b3dbaa37-00bd-48e9-9803-2d1d5c1deadd"
      },
      "source": [
        "nltk.download('punkt')\n",
        "df['text']= [word_tokenize(w) for w in df['text']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YJmWR1ES_1q"
      },
      "source": [
        "df['text']=[str(w) for w in df['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtkkPbQS_1q"
      },
      "source": [
        "kf=RepeatedKFold(n_splits=3,n_repeats=7, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O2G-UVQS_1q"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = model_selection.train_test_split(df['text'],df['tar'],test_size=0.3,random_state=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0xT2GsIS_1q",
        "outputId": "b2ee2d9e-0c93-4880-ec3d-a7b3926463a3"
      },
      "source": [
        "count_vect = CountVectorizer(max_features=5000)\n",
        "count_vect.fit(df['text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nGa-vNeSUwM"
      },
      "source": [
        "**Bag of Words models with no preprocessing(no stop words and punctuation removal) :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjkDLdcKS_1q"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        "\n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "    SVM.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_SVM = SVM.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_SVM, ytest)*100)\n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiMERWt3S_1q",
        "outputId": "ed83d215-eee7-4fb0-c4a8-82ada8e92be1"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81.40929535232384,\n",
              " 84.55772113943029,\n",
              " 82.58258258258259,\n",
              " 82.45877061469265,\n",
              " 83.50824587706147,\n",
              " 80.48048048048048,\n",
              " 81.25937031484258,\n",
              " 82.90854572713643,\n",
              " 83.33333333333334,\n",
              " 80.50974512743629,\n",
              " 82.3088455772114,\n",
              " 81.23123123123122,\n",
              " 82.90854572713643,\n",
              " 83.65817091454272,\n",
              " 81.83183183183183,\n",
              " 80.8095952023988,\n",
              " 83.20839580209895,\n",
              " 81.38138138138137,\n",
              " 80.0599700149925,\n",
              " 84.55772113943029,\n",
              " 82.43243243243244]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl0h5SlHS_1q",
        "outputId": "9159de2d-a7a4-4702-b6bf-574378f2d164"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.25696246685753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbIM4ROxS_1r"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        "\n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    ada = AdaBoostClassifier(n_estimators=1500)\n",
        "    ada.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_ada = ada.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_ada, ytest)*100)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o3Grl7-S_1r",
        "outputId": "37eaff40-d1ab-4b86-8535-10f95a40092b"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81.25937031484258,\n",
              " 83.65817091454272,\n",
              " 80.78078078078079,\n",
              " 80.20989505247377,\n",
              " 84.25787106446776,\n",
              " 82.43243243243244,\n",
              " 81.40929535232384,\n",
              " 82.6086956521739,\n",
              " 82.73273273273273,\n",
              " 83.65817091454272,\n",
              " 82.3088455772114,\n",
              " 81.83183183183183,\n",
              " 82.00899550224887,\n",
              " 84.70764617691154,\n",
              " 81.53153153153153,\n",
              " 81.70914542728636,\n",
              " 82.15892053973015,\n",
              " 81.98198198198197,\n",
              " 82.75862068965517,\n",
              " 79.01049475262369,\n",
              " 81.68168168168168]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnG1OyuyS_1r",
        "outputId": "252c6089-6db7-4bd8-ed29-4d9f7b28c48b"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.12843385257177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuAc3cKwS_1r"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        " \n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    gf = GradientBoostingClassifier(n_estimators=1500)\n",
        "    gf.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_gf = gf.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_gf, ytest)*100)\n",
        "    \n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdyfMHzhS_1s",
        "outputId": "c3670c9b-3245-4735-fda7-a4ac24056456"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81.85907046476761,\n",
              " 83.50824587706147,\n",
              " 80.18018018018019,\n",
              " 80.35982008995502,\n",
              " 84.55772113943029,\n",
              " 83.03303303303304,\n",
              " 85.30734632683658,\n",
              " 81.10944527736132,\n",
              " 82.13213213213213,\n",
              " 85.00749625187406,\n",
              " 81.55922038980509,\n",
              " 82.88288288288288,\n",
              " 79.01049475262369,\n",
              " 84.40779610194903,\n",
              " 81.38138138138137,\n",
              " 81.40929535232384,\n",
              " 81.55922038980509,\n",
              " 81.23123123123122,\n",
              " 82.75862068965517,\n",
              " 83.05847076461768,\n",
              " 84.68468468468468]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZB2Bz9WS_1s",
        "outputId": "e6f29892-9a38-4e61-bf34-60fb919ebf44"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.4284661615996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsrx9AFIS_1s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Z3qfHMS_1s",
        "outputId": "b8522a48-d430-4108-db0d-4a3fb247b52b"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0sm2JQxS_1s"
      },
      "source": [
        "stop_words = list(set(stopwords.words('english')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5HUsYf_S_1s"
      },
      "source": [
        "fd=pd.concat([df1,df2])\n",
        "fd=fd.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "bvRezSsSS_1s",
        "outputId": "43c0d1e5-5be7-4f0a-a5ef-eddf3d1cb315"
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review damn th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  plot : two teen couples go to a church party ,...    0\n",
              "1  the happy bastard's quick movie review damn th...    0\n",
              "2  it is movies like these that make a jaded movi...    0\n",
              "3   \" quest for camelot \" is warner bros . ' firs...    0\n",
              "4  synopsis : a mentally unstable man undergoing ...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUhKARrHS_1s"
      },
      "source": [
        "l=[]\n",
        "for i in fd['text']:\n",
        "    li=[]\n",
        "    j=i.split()\n",
        "    for k in j:\n",
        "        if k not in stop_words and k not in punctuation:\n",
        "            li.append(k.lower())\n",
        "    l=l+[li]\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "fGi-WU1-S_1s",
        "outputId": "2d04e051-82ae-4a1f-f8c5-3e6b03199b59"
      },
      "source": [
        "fd['text'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'plot : two teen couples go to a church party , drink and then drive . they get into an accident . one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . what\\'s the deal ? watch the movie and \" sorta \" find out . . . critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . they seem to have taken this pretty neat concept , but executed it terribly . so what are the problems with the movie ? well , its main problem is that it\\'s simply too jumbled . it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what\\'s going on . there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . now i personally don\\'t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film\\'s biggest problem . it\\'s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . and do they make things entertaining , thrilling or even engaging , in the meantime ? not really . the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn\\'t the make the film all that more entertaining . i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! okay , we get it . . . there are people chasing her and we don\\'t know who they are . do we really need to see it over and over again ? how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? apparently , the studio took this film away from its director and chopped it up themselves , and it shows . there might\\'ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character\\'s unraveling . overall , the film doesn\\'t stick because it doesn\\'t entertain , it\\'s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . oh , and by the way , this is not a horror or teen slasher flick . . . it\\'s just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . it also wrapped production two years ago and has been sitting on the shelves ever since . whatever . . . skip it ! where\\'s joblo coming from ? a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt0H3sLUS_1t",
        "outputId": "78b4381d-bdad-4c56-8e42-6fce8d71ef11"
      },
      "source": [
        "l[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot',\n",
              " 'two',\n",
              " 'teen',\n",
              " 'couples',\n",
              " 'go',\n",
              " 'church',\n",
              " 'party',\n",
              " 'drink',\n",
              " 'drive',\n",
              " 'get',\n",
              " 'accident',\n",
              " 'one',\n",
              " 'guys',\n",
              " 'dies',\n",
              " 'girlfriend',\n",
              " 'continues',\n",
              " 'see',\n",
              " 'life',\n",
              " 'nightmares',\n",
              " \"what's\",\n",
              " 'deal',\n",
              " 'watch',\n",
              " 'movie',\n",
              " 'sorta',\n",
              " 'find',\n",
              " 'critique',\n",
              " 'mind-fuck',\n",
              " 'movie',\n",
              " 'teen',\n",
              " 'generation',\n",
              " 'touches',\n",
              " 'cool',\n",
              " 'idea',\n",
              " 'presents',\n",
              " 'bad',\n",
              " 'package',\n",
              " 'makes',\n",
              " 'review',\n",
              " 'even',\n",
              " 'harder',\n",
              " 'one',\n",
              " 'write',\n",
              " 'since',\n",
              " 'generally',\n",
              " 'applaud',\n",
              " 'films',\n",
              " 'attempt',\n",
              " 'break',\n",
              " 'mold',\n",
              " 'mess',\n",
              " 'head',\n",
              " 'lost',\n",
              " 'highway',\n",
              " 'memento',\n",
              " 'good',\n",
              " 'bad',\n",
              " 'ways',\n",
              " 'making',\n",
              " 'types',\n",
              " 'films',\n",
              " 'folks',\n",
              " 'snag',\n",
              " 'one',\n",
              " 'correctly',\n",
              " 'seem',\n",
              " 'taken',\n",
              " 'pretty',\n",
              " 'neat',\n",
              " 'concept',\n",
              " 'executed',\n",
              " 'terribly',\n",
              " 'problems',\n",
              " 'movie',\n",
              " 'well',\n",
              " 'main',\n",
              " 'problem',\n",
              " 'simply',\n",
              " 'jumbled',\n",
              " 'starts',\n",
              " 'normal',\n",
              " 'downshifts',\n",
              " 'fantasy',\n",
              " 'world',\n",
              " 'audience',\n",
              " 'member',\n",
              " 'idea',\n",
              " \"what's\",\n",
              " 'going',\n",
              " 'dreams',\n",
              " 'characters',\n",
              " 'coming',\n",
              " 'back',\n",
              " 'dead',\n",
              " 'others',\n",
              " 'look',\n",
              " 'like',\n",
              " 'dead',\n",
              " 'strange',\n",
              " 'apparitions',\n",
              " 'disappearances',\n",
              " 'looooot',\n",
              " 'chase',\n",
              " 'scenes',\n",
              " 'tons',\n",
              " 'weird',\n",
              " 'things',\n",
              " 'happen',\n",
              " 'simply',\n",
              " 'explained',\n",
              " 'personally',\n",
              " 'mind',\n",
              " 'trying',\n",
              " 'unravel',\n",
              " 'film',\n",
              " 'every',\n",
              " 'give',\n",
              " 'clue',\n",
              " 'get',\n",
              " 'kind',\n",
              " 'fed',\n",
              " \"film's\",\n",
              " 'biggest',\n",
              " 'problem',\n",
              " 'obviously',\n",
              " 'got',\n",
              " 'big',\n",
              " 'secret',\n",
              " 'hide',\n",
              " 'seems',\n",
              " 'want',\n",
              " 'hide',\n",
              " 'completely',\n",
              " 'final',\n",
              " 'five',\n",
              " 'minutes',\n",
              " 'make',\n",
              " 'things',\n",
              " 'entertaining',\n",
              " 'thrilling',\n",
              " 'even',\n",
              " 'engaging',\n",
              " 'meantime',\n",
              " 'really',\n",
              " 'sad',\n",
              " 'part',\n",
              " 'arrow',\n",
              " 'dig',\n",
              " 'flicks',\n",
              " 'like',\n",
              " 'actually',\n",
              " 'figured',\n",
              " 'half-way',\n",
              " 'point',\n",
              " 'strangeness',\n",
              " 'start',\n",
              " 'make',\n",
              " 'little',\n",
              " 'bit',\n",
              " 'sense',\n",
              " 'still',\n",
              " 'make',\n",
              " 'film',\n",
              " 'entertaining',\n",
              " 'guess',\n",
              " 'bottom',\n",
              " 'line',\n",
              " 'movies',\n",
              " 'like',\n",
              " 'always',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'audience',\n",
              " 'even',\n",
              " 'given',\n",
              " 'secret',\n",
              " 'password',\n",
              " 'enter',\n",
              " 'world',\n",
              " 'understanding',\n",
              " 'mean',\n",
              " 'showing',\n",
              " 'melissa',\n",
              " 'sagemiller',\n",
              " 'running',\n",
              " 'away',\n",
              " 'visions',\n",
              " '20',\n",
              " 'minutes',\n",
              " 'throughout',\n",
              " 'movie',\n",
              " 'plain',\n",
              " 'lazy',\n",
              " 'okay',\n",
              " 'get',\n",
              " 'people',\n",
              " 'chasing',\n",
              " 'know',\n",
              " 'really',\n",
              " 'need',\n",
              " 'see',\n",
              " 'giving',\n",
              " 'us',\n",
              " 'different',\n",
              " 'scenes',\n",
              " 'offering',\n",
              " 'insight',\n",
              " 'strangeness',\n",
              " 'going',\n",
              " 'movie',\n",
              " 'apparently',\n",
              " 'studio',\n",
              " 'took',\n",
              " 'film',\n",
              " 'away',\n",
              " 'director',\n",
              " 'chopped',\n",
              " 'shows',\n",
              " \"might've\",\n",
              " 'pretty',\n",
              " 'decent',\n",
              " 'teen',\n",
              " 'mind-fuck',\n",
              " 'movie',\n",
              " 'somewhere',\n",
              " 'guess',\n",
              " 'suits',\n",
              " 'decided',\n",
              " 'turning',\n",
              " 'music',\n",
              " 'video',\n",
              " 'little',\n",
              " 'edge',\n",
              " 'would',\n",
              " 'make',\n",
              " 'sense',\n",
              " 'actors',\n",
              " 'pretty',\n",
              " 'good',\n",
              " 'part',\n",
              " 'although',\n",
              " 'wes',\n",
              " 'bentley',\n",
              " 'seemed',\n",
              " 'playing',\n",
              " 'exact',\n",
              " 'character',\n",
              " 'american',\n",
              " 'beauty',\n",
              " 'new',\n",
              " 'neighborhood',\n",
              " 'biggest',\n",
              " 'kudos',\n",
              " 'go',\n",
              " 'sagemiller',\n",
              " 'holds',\n",
              " 'throughout',\n",
              " 'entire',\n",
              " 'film',\n",
              " 'actually',\n",
              " 'feeling',\n",
              " \"character's\",\n",
              " 'unraveling',\n",
              " 'overall',\n",
              " 'film',\n",
              " 'stick',\n",
              " 'entertain',\n",
              " 'confusing',\n",
              " 'rarely',\n",
              " 'excites',\n",
              " 'feels',\n",
              " 'pretty',\n",
              " 'redundant',\n",
              " 'runtime',\n",
              " 'despite',\n",
              " 'pretty',\n",
              " 'cool',\n",
              " 'ending',\n",
              " 'explanation',\n",
              " 'craziness',\n",
              " 'came',\n",
              " 'oh',\n",
              " 'way',\n",
              " 'horror',\n",
              " 'teen',\n",
              " 'slasher',\n",
              " 'flick',\n",
              " 'packaged',\n",
              " 'look',\n",
              " 'way',\n",
              " 'someone',\n",
              " 'apparently',\n",
              " 'assuming',\n",
              " 'genre',\n",
              " 'still',\n",
              " 'hot',\n",
              " 'kids',\n",
              " 'also',\n",
              " 'wrapped',\n",
              " 'production',\n",
              " 'two',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'sitting',\n",
              " 'shelves',\n",
              " 'ever',\n",
              " 'since',\n",
              " 'whatever',\n",
              " 'skip',\n",
              " \"where's\",\n",
              " 'joblo',\n",
              " 'coming',\n",
              " 'nightmare',\n",
              " 'elm',\n",
              " 'street',\n",
              " '3',\n",
              " '7/10',\n",
              " 'blair',\n",
              " 'witch',\n",
              " '2',\n",
              " '7/10',\n",
              " 'crow',\n",
              " '9/10',\n",
              " 'crow',\n",
              " 'salvation',\n",
              " '4/10',\n",
              " 'lost',\n",
              " 'highway',\n",
              " '10/10',\n",
              " 'memento',\n",
              " '10/10',\n",
              " 'others',\n",
              " '9/10',\n",
              " 'stir',\n",
              " 'echoes',\n",
              " '8/10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFtrKBYbS_1t"
      },
      "source": [
        "fd['text'] = pd.Series(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "12MkEJwdS_1t",
        "outputId": "b1381ddd-30f8-4561-bdf9-5021bf59eb99"
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[plot, two, teen, couples, go, church, party, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[happy, bastard's, quick, movie, review, damn,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[movies, like, make, jaded, movie, viewer, tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[quest, camelot, warner, bros, first, feature-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[synopsis, mentally, unstable, man, undergoing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  [plot, two, teen, couples, go, church, party, ...    0\n",
              "1  [happy, bastard's, quick, movie, review, damn,...    0\n",
              "2  [movies, like, make, jaded, movie, viewer, tha...    0\n",
              "3  [quest, camelot, warner, bros, first, feature-...    0\n",
              "4  [synopsis, mentally, unstable, man, undergoing...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUF5mnmAS_1t"
      },
      "source": [
        "fd['text']=[str(w) for w in fd['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "JZHaL36Lp8lp",
        "outputId": "61d095c5-cab5-4f60-e73f-bfd67ba00911"
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['plot', 'two', 'teen', 'couples', 'go', 'chur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['happy', \"bastard's\", 'quick', 'movie', 'revi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['movies', 'like', 'make', 'jaded', 'movie', '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['quest', 'camelot', 'warner', 'bros', 'first'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['synopsis', 'mentally', 'unstable', 'man', 'u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  ['plot', 'two', 'teen', 'couples', 'go', 'chur...    0\n",
              "1  ['happy', \"bastard's\", 'quick', 'movie', 'revi...    0\n",
              "2  ['movies', 'like', 'make', 'jaded', 'movie', '...    0\n",
              "3  ['quest', 'camelot', 'warner', 'bros', 'first'...    0\n",
              "4  ['synopsis', 'mentally', 'unstable', 'man', 'u...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tNzuP8ZS_1t"
      },
      "source": [
        "kf=RepeatedKFold(n_splits=3,n_repeats=7, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oembYl76S_1t"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = model_selection.train_test_split(fd['text'],fd['tar'],test_size=0.3,random_state=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5-JXXDoToEh"
      },
      "source": [
        "**Bag of Words Model with preprocessing(stop words and punctuation removed)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsMG6ynS_1t"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "    SVM.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_SVM = SVM.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_SVM, ytest)*100)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm4g1DDMS_1t",
        "outputId": "f2eaa6be-6a72-463d-f4c5-a9152ce56928"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[82.90854572713643,\n",
              " 85.45727136431785,\n",
              " 83.03303303303304,\n",
              " 82.3088455772114,\n",
              " 84.25787106446776,\n",
              " 82.58258258258259,\n",
              " 81.70914542728636,\n",
              " 80.50974512743629,\n",
              " 82.73273273273273,\n",
              " 81.55922038980509,\n",
              " 81.25937031484258,\n",
              " 82.73273273273273,\n",
              " 83.50824587706147,\n",
              " 81.70914542728636,\n",
              " 83.18318318318319,\n",
              " 80.65967016491754,\n",
              " 84.25787106446776,\n",
              " 82.28228228228228,\n",
              " 78.71064467766116,\n",
              " 83.65817091454272,\n",
              " 81.98198198198197]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSoV9PzQS_1t",
        "outputId": "09da078c-53ac-4383-9438-848d030e807a"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.4286805546176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEatChIaS_1t"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    ada = AdaBoostClassifier(n_estimators=1500)\n",
        "    ada.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_ada = ada.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_ada, ytest)*100)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4aWaeXkS_1t",
        "outputId": "60137c04-fd10-482a-f94e-eb36397732b3"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81.70914542728636,\n",
              " 82.00899550224887,\n",
              " 81.53153153153153,\n",
              " 81.10944527736132,\n",
              " 82.45877061469265,\n",
              " 82.43243243243244,\n",
              " 82.90854572713643,\n",
              " 79.16041979010495,\n",
              " 82.58258258258259,\n",
              " 83.35832083958022,\n",
              " 79.3103448275862,\n",
              " 79.12912912912913,\n",
              " 80.0599700149925,\n",
              " 82.00899550224887,\n",
              " 80.48048048048048,\n",
              " 82.3088455772114,\n",
              " 84.25787106446776,\n",
              " 81.23123123123122,\n",
              " 81.40929535232384,\n",
              " 79.76011994002998,\n",
              " 83.63363363363364]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgGD1nejS_1u",
        "outputId": "2b71794c-ce9f-4bc4-96c6-99b0cd67ee20"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.5642907846806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdiqrzr6S_1u"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    gf = GradientBoostingClassifier(n_estimators=1500)\n",
        "    gf.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_gf = gf.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_gf, ytest)*100)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_KCDVacS_1u",
        "outputId": "b0c8f320-b08d-43cf-c70f-7a950aecf53e"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[82.6086956521739,\n",
              " 83.95802098950524,\n",
              " 82.73273273273273,\n",
              " 80.20989505247377,\n",
              " 83.95802098950524,\n",
              " 80.33033033033034,\n",
              " 83.65817091454272,\n",
              " 79.91004497751123,\n",
              " 81.68168168168168,\n",
              " 84.55772113943029,\n",
              " 79.61019490254873,\n",
              " 82.13213213213213,\n",
              " 79.16041979010495,\n",
              " 83.80809595202399,\n",
              " 80.93093093093093,\n",
              " 80.0599700149925,\n",
              " 82.75862068965517,\n",
              " 81.83183183183183,\n",
              " 81.40929535232384,\n",
              " 82.3088455772114,\n",
              " 83.48348348348348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLhbUIRJS_1u",
        "outputId": "8e29f40a-85b1-479b-d1ca-7d275f08cdc9"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.95710167224411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGRG_ipBS_1u"
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(df['text'])\n",
        "xtraintf = Tfidf_vect.transform(xtrain)\n",
        "xtesttf = Tfidf_vect.transform(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRcRt_t-S_1u"
      },
      "source": [
        "kf=RepeatedKFold(n_splits=3,n_repeats=7, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1rSSpES_1u"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = model_selection.train_test_split(df['text'],df['tar'],test_size=0.3,random_state=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9UpGxc1UCFU"
      },
      "source": [
        "**TF-IDF Models with no preprocessing :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnpWwMJ3S_1u"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    tf_vect = TfidfVectorizer(max_features=16165)\n",
        "    xtrain_c=tf_vect.fit_transform(xtrain)\n",
        "    xtest_c=tf_vect.transform(xtest)\n",
        "    \n",
        "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "    SVM.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_SVM = SVM.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_SVM, ytest)*100)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUt_gYs3S_1u",
        "outputId": "0a28b468-f8a7-4ff6-fb80-049742d51d10"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[82.45877061469265,\n",
              " 86.20689655172413,\n",
              " 85.28528528528528,\n",
              " 83.50824587706147,\n",
              " 85.75712143928035,\n",
              " 82.58258258258259,\n",
              " 83.80809595202399,\n",
              " 83.20839580209895,\n",
              " 85.13513513513513,\n",
              " 84.1079460269865,\n",
              " 82.6086956521739,\n",
              " 84.53453453453453,\n",
              " 84.25787106446776,\n",
              " 85.6071964017991,\n",
              " 84.53453453453453,\n",
              " 82.45877061469265,\n",
              " 84.1079460269865,\n",
              " 84.23423423423422,\n",
              " 83.05847076461768,\n",
              " 86.20689655172413,\n",
              " 83.33333333333334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_vQFmRSS_1v",
        "outputId": "69866996-5aa6-45cd-85b3-4f9fa3b90345"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.14290280856997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIKXZRHxS_1v"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    tf_vect = TfidfVectorizer(max_features=16165)\n",
        "    xtrain_c=tf_vect.fit_transform(xtrain)\n",
        "    xtest_c=tf_vect.transform(xtest)\n",
        "    \n",
        "    ada = AdaBoostClassifier(n_estimators=1500)\n",
        "    ada.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_ada = ada.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_ada, ytest)*100)\n",
        "    \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_laIe60eS_1v",
        "outputId": "006d74fe-cdac-4c2c-8929-af8f39f6e8de"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81.70914542728636,\n",
              " 82.45877061469265,\n",
              " 83.93393393393393,\n",
              " 82.15892053973015,\n",
              " 83.50824587706147,\n",
              " 83.33333333333334,\n",
              " 82.00899550224887,\n",
              " 78.86056971514243,\n",
              " 83.03303303303304,\n",
              " 83.95802098950524,\n",
              " 80.8095952023988,\n",
              " 81.23123123123122,\n",
              " 82.3088455772114,\n",
              " 84.25787106446776,\n",
              " 81.08108108108108,\n",
              " 82.90854572713643,\n",
              " 82.6086956521739,\n",
              " 82.43243243243244,\n",
              " 81.55922038980509,\n",
              " 80.95952023988005,\n",
              " 81.53153153153153]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YifB2MmMS_1v",
        "outputId": "44099024-68ac-476f-fd93-f6059a2c46b6"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.22150186168177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsZAR8qS_1v"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(df['text'],df['tar']):\n",
        "    xtrain,xtest=df['text'][train_idx],df['text'][test_idx]\n",
        "    ytrain,ytest=df['tar'][train_idx],df['tar'][test_idx]\n",
        "    \n",
        "    tf_vect = TfidfVectorizer(max_features=16165)\n",
        "    xtrain_c=tf_vect.fit_transform(xtrain)\n",
        "    xtest_c=tf_vect.transform(xtest)\n",
        "    \n",
        "    gf = GradientBoostingClassifier(n_estimators=1500)\n",
        "    gf.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_gf = gf.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_gf, ytest)*100)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8lt2J6-S_1v",
        "outputId": "3ab24ea9-c171-478c-ff88-396213aee642"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[80.20989505247377,\n",
              " 84.25787106446776,\n",
              " 81.53153153153153,\n",
              " 80.20989505247377,\n",
              " 82.45877061469265,\n",
              " 82.43243243243244,\n",
              " 83.80809595202399,\n",
              " 80.35982008995502,\n",
              " 82.58258258258259,\n",
              " 83.20839580209895,\n",
              " 81.85907046476761,\n",
              " 83.33333333333334,\n",
              " 81.10944527736132,\n",
              " 83.35832083958022,\n",
              " 80.33033033033034,\n",
              " 79.01049475262369,\n",
              " 80.65967016491754,\n",
              " 82.58258258258259,\n",
              " 80.95952023988005,\n",
              " 82.45877061469265,\n",
              " 82.88288288288288]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oYPPGK4S_1v",
        "outputId": "7897bfc4-88ee-4f67-d869-5cad1b3ae88b"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.88589103131831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVbnwVvHnr33"
      },
      "source": [
        "fd=pd.concat([df1,df2])\n",
        "fd=fd.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjbsuwzYnsKM"
      },
      "source": [
        "l=[]\n",
        "for i in fd['text']:\n",
        "    li=[]\n",
        "    j=i.split()\n",
        "    for k in j:\n",
        "        if k not in stop_words and k not in punctuation:\n",
        "            li.append(k.lower())\n",
        "    l=l+[li]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyKaRc2vnsQ-"
      },
      "source": [
        "fd['text'] = pd.Series(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILESDDklnsm5",
        "outputId": "c458838c-7464-4d24-b836-1d3039df8a4d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV0-s30zou9i"
      },
      "source": [
        "def lemmatize(s):\n",
        "    return [str(lemmatizer.lemmatize(w)) for w in s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY30zFOoovEV"
      },
      "source": [
        "fd['text'] = fd.text.apply(lemmatize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PJpQCPxuINJ"
      },
      "source": [
        "fd['text']=[str(w) for w in fd['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YMEAqsDupf5q",
        "outputId": "553461a0-3d51-4b61-fb4b-fd75ffc3c8a4"
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['plot', 'two', 'teen', 'couple', 'go', 'churc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['happy', \"bastard's\", 'quick', 'movie', 'revi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['movie', 'like', 'make', 'jaded', 'movie', 'v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['quest', 'camelot', 'warner', 'bros', 'first'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['synopsis', 'mentally', 'unstable', 'man', 'u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  tar\n",
              "0  ['plot', 'two', 'teen', 'couple', 'go', 'churc...    0\n",
              "1  ['happy', \"bastard's\", 'quick', 'movie', 'revi...    0\n",
              "2  ['movie', 'like', 'make', 'jaded', 'movie', 'v...    0\n",
              "3  ['quest', 'camelot', 'warner', 'bros', 'first'...    0\n",
              "4  ['synopsis', 'mentally', 'unstable', 'man', 'u...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EjtbYiWUbDd"
      },
      "source": [
        "**TF-IDF Models with preprocessing(stop words and punctuation removal and Lemmatization) :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL1--I67pgJy"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    tf_vect = TfidfVectorizer(max_features=16165)\n",
        "    xtrain_c=tf_vect.fit_transform(xtrain)\n",
        "    xtest_c=tf_vect.transform(xtest)\n",
        "    \n",
        "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "    SVM.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_SVM = SVM.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_SVM, ytest)*100)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPRzDvxHu6O3",
        "outputId": "15fa6258-8ac1-4da9-880f-c153545c17dd"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[84.8575712143928,\n",
              " 86.05697151424287,\n",
              " 83.78378378378379,\n",
              " 84.40779610194903,\n",
              " 85.00749625187406,\n",
              " 81.68168168168168,\n",
              " 83.35832083958022,\n",
              " 83.05847076461768,\n",
              " 84.98498498498499,\n",
              " 82.90854572713643,\n",
              " 82.90854572713643,\n",
              " 84.83483483483484,\n",
              " 83.50824587706147,\n",
              " 84.40779610194903,\n",
              " 85.58558558558559,\n",
              " 79.61019490254873,\n",
              " 84.55772113943029,\n",
              " 84.98498498498499,\n",
              " 82.6086956521739,\n",
              " 85.15742128935531,\n",
              " 83.48348348348348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4tuVRVHu9Uh",
        "outputId": "a2f08638-ae8e-4d01-a10e-2bf3d3649d4a"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.89300630679944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N8OMDDtw3Cd"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    count_vect = CountVectorizer(max_features=16165)\n",
        "    xtrain_c=count_vect.fit_transform(xtrain)\n",
        "    xtest_c=count_vect.transform(xtest)\n",
        "    \n",
        "    ada = AdaBoostClassifier(n_estimators=1500)\n",
        "    ada.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_ada = ada.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_ada, ytest)*100)\n",
        "    \n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNpLZy8i0TFR",
        "outputId": "40596920-d05b-4117-e9e8-7aec21e16da5"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[83.20839580209895,\n",
              " 83.65817091454272,\n",
              " 81.38138138138137,\n",
              " 81.10944527736132,\n",
              " 83.65817091454272,\n",
              " 80.78078078078079,\n",
              " 82.00899550224887,\n",
              " 79.3103448275862,\n",
              " 81.83183183183183,\n",
              " 82.90854572713643,\n",
              " 79.46026986506747,\n",
              " 79.72972972972973,\n",
              " 78.41079460269866,\n",
              " 82.90854572713643,\n",
              " 80.18018018018019,\n",
              " 79.76011994002998,\n",
              " 85.45727136431785,\n",
              " 79.72972972972973,\n",
              " 81.55922038980509,\n",
              " 79.46026986506747,\n",
              " 81.98198198198197]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2O70l510VmT",
        "outputId": "b561739b-cc35-49ec-d220-14262e1c4015"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.35686553977409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7xoAeSx2rih"
      },
      "source": [
        "acc=[]\n",
        "for train_idx, test_idx in kf.split(fd['text'],fd['tar']):\n",
        "    xtrain,xtest=fd['text'][train_idx],fd['text'][test_idx]\n",
        "    ytrain,ytest=fd['tar'][train_idx],fd['tar'][test_idx]\n",
        "    \n",
        "    tf_vect = TfidfVectorizer(max_features=16165)\n",
        "    xtrain_c=tf_vect.fit_transform(xtrain)\n",
        "    xtest_c=tf_vect.transform(xtest)\n",
        "    \n",
        "    gf = GradientBoostingClassifier(n_estimators=1500)\n",
        "    gf.fit(xtrain_c,ytrain)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions_gf = gf.predict(xtest_c)\n",
        "    # Use accuracy_score function to get the accuracy\n",
        "    acc.append(accuracy_score(predictions_gf, ytest)*100)\n",
        "    \n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zRV8Oi99-MW",
        "outputId": "46119e1e-db50-4d23-fb05-8b9f33adb18f"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[80.8095952023988,\n",
              " 82.45877061469265,\n",
              " 78.52852852852853,\n",
              " 81.70914542728636,\n",
              " 80.0599700149925,\n",
              " 80.33033033033034,\n",
              " 81.55922038980509,\n",
              " 79.91004497751123,\n",
              " 81.68168168168168,\n",
              " 82.90854572713643,\n",
              " 79.3103448275862,\n",
              " 80.03003003003003,\n",
              " 80.50974512743629,\n",
              " 81.40929535232384,\n",
              " 80.03003003003003,\n",
              " 79.3103448275862,\n",
              " 80.50974512743629,\n",
              " 82.88288288288288,\n",
              " 81.10944527736132,\n",
              " 81.70914542728636,\n",
              " 83.33333333333334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt9szVha9_WY",
        "outputId": "c5b0623b-7399-4028-fb9e-a6b678a23887"
      },
      "source": [
        "sum(acc)/len(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.95715119703125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjsq-IhwUuJE"
      },
      "source": [
        "**Building the LSTM Model :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWlu7nGO9x6f"
      },
      "source": [
        "def preprocess(s):\n",
        "\n",
        "    s = re.sub('[^a-zA-Z]', ' ', s) \n",
        "    s = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', s)  \n",
        "    s = re.sub(r'\\s+', ' ', s)  \n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4K-nX_k-Bsm"
      },
      "source": [
        "df=pd.concat([df1,df2],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2RLWwwS-Bxs"
      },
      "source": [
        "df=df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHapoufm-B3Y"
      },
      "source": [
        "X = []\n",
        "sentences = list(df['text'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess(sen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "5g5e5Rv_-B82",
        "outputId": "d5b308b4-8961-45f7-c630-8bc5a2ac84f2"
      },
      "source": [
        "X[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' quest for camelot is warner bros first feature length fully animated attempt to steal clout from disney cartoon empire but the mouse has no reason to be worried the only other recent challenger to their throne was last fall promising if flawed th century fox production anastasia but disney hercules with its lively cast and colorful palate had her beat hands down when it came time to crown best piece of animation this year it no contest as quest for camelot is pretty much dead on arrival even the magic kingdom at its most mediocre that be pocahontas for those of you keeping score isn nearly as dull as this the story revolves around the adventures of free spirited kayley voiced by jessalyn gilsig the early teen daughter of belated knight from king arthur round table kayley only dream is to follow in her father footsteps and she gets her chance when evil warlord ruber gary oldman an ex round table member gone bad steals arthur magical sword excalibur and accidentally loses it in dangerous booby trapped forest with the help of hunky blind timberland dweller garrett carey elwes and two headed dragon eric idle and don rickles that always arguing with itself kayley just might be able to break the medieval sexist mold and prove her worth as fighter on arthur side quest for camelot is missing pure showmanship an essential element if it ever expected to climb to the high ranks of disney there nothing here that differentiates quest from something you see on any given saturday morning cartoon subpar animation instantly forgettable songs poorly integrated computerized footage compare kayley and garrett run in with the angry ogre to herc battle with the hydra rest my case even the characters stink none of them are remotely interesting so much that the film becomes race to see which one can out bland the others in the end it a tie they all win that dragon comedy shtick is awfully cloying but at least it shows signs of pulse at least fans of the early tgif television line up will be thrilled to find jaleel urkel white and bronson balki pinchot sharing the same footage few scenes are nicely realized though m at loss to recall enough to be specific and the actors providing the voice talent are enthusiastic though most are paired up with singers who don sound thing like them for their big musical moments jane seymour and celine dion but one must strain through too much of this mess to find the good aside from the fact that children will probably be as bored watching this as adults quest for camelot most grievous error is its complete lack of personality and personality we learn from this mess goes very long way '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODihL0N6-CCT"
      },
      "source": [
        "y = df['tar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw4HqgY8-3k2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y,test_size=0.3,random_state=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV2z99Jv-3rs"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=24000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mne1vqq_-3xd"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb7TBE1X-33k"
      },
      "source": [
        "glove='/content/gdrive/My Drive/glove.6B.100d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMts5quR-39e"
      },
      "source": [
        "glove_file = open(glove, encoding=\"utf8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6qhiwFt-4Nj"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open(glove, encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDPd5Zgs-4TY"
      },
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiQHUZNd_ZBK"
      },
      "source": [
        "kf=RepeatedKFold(n_splits=3,n_repeats=7, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2kZMgawAQ-8"
      },
      "source": [
        "from keras.layers.recurrent import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWdvd0QDfot"
      },
      "source": [
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNByeQKL_ZGs",
        "outputId": "400d0f3c-04f3-4021-9354-09b105a6e4e8"
      },
      "source": [
        "fold = 1\n",
        "acc = []\n",
        "loss = []\n",
        "for train, test in kf.split(X,y):\n",
        "\n",
        "  model = Sequential()\n",
        "  embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "  model.add(embedding_layer)\n",
        "  model.add(LSTM(256, return_sequences=True))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(LSTM(128, return_sequences=True))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(LSTM(32))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "  history = model.fit(X[train], y[train], batch_size=256, epochs=25, verbose=1, validation_split=0.3)\n",
        "\n",
        "  scores = model.evaluate(X[test], y[test], verbose=1)\n",
        "  print(f'Score for fold {fold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc.append(scores[1] * 100)\n",
        "  loss.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold = fold + 1\n",
        "\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc)} (+- {np.std(acc)})')\n",
        "print(f'> Loss: {np.mean(loss)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.6994 - acc: 0.5305 - val_loss: 0.7243 - val_acc: 0.4900\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.6888 - acc: 0.5338 - val_loss: 0.6847 - val_acc: 0.5350\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6713 - acc: 0.5820 - val_loss: 0.6843 - val_acc: 0.5450\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6540 - acc: 0.6120 - val_loss: 0.6507 - val_acc: 0.6025\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6231 - acc: 0.6517 - val_loss: 0.6368 - val_acc: 0.6625\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6602 - acc: 0.6367 - val_loss: 0.6373 - val_acc: 0.6400\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6313 - acc: 0.6559 - val_loss: 0.6395 - val_acc: 0.6450\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6123 - acc: 0.6902 - val_loss: 0.6483 - val_acc: 0.6275\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5982 - acc: 0.6838 - val_loss: 0.6097 - val_acc: 0.6450\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5644 - acc: 0.7095 - val_loss: 0.6047 - val_acc: 0.6875\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5528 - acc: 0.7213 - val_loss: 0.5667 - val_acc: 0.7250\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5214 - acc: 0.7395 - val_loss: 0.6684 - val_acc: 0.6175\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5532 - acc: 0.7299 - val_loss: 0.5705 - val_acc: 0.6950\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5294 - acc: 0.7353 - val_loss: 0.5629 - val_acc: 0.7050\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5001 - acc: 0.7471 - val_loss: 0.5646 - val_acc: 0.7150\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4784 - acc: 0.7792 - val_loss: 0.6387 - val_acc: 0.6525\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4593 - acc: 0.7878 - val_loss: 0.5733 - val_acc: 0.7125\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4578 - acc: 0.7974 - val_loss: 0.5872 - val_acc: 0.7125\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4357 - acc: 0.8006 - val_loss: 0.6079 - val_acc: 0.6825\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4285 - acc: 0.8135 - val_loss: 0.5928 - val_acc: 0.6950\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3698 - acc: 0.8446 - val_loss: 0.5755 - val_acc: 0.7200\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3395 - acc: 0.8628 - val_loss: 0.6725 - val_acc: 0.6875\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3351 - acc: 0.8542 - val_loss: 0.6485 - val_acc: 0.6825\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.2819 - acc: 0.8896 - val_loss: 0.9383 - val_acc: 0.5825\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4628 - acc: 0.7835 - val_loss: 0.7078 - val_acc: 0.6575\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7886 - acc: 0.6207\n",
            "Score for fold 1: loss of 0.7886078953742981; acc of 62.068963050842285%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7337 - acc: 0.4962 - val_loss: 0.7056 - val_acc: 0.4825\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6955 - acc: 0.5102 - val_loss: 0.6872 - val_acc: 0.5350\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6810 - acc: 0.5863 - val_loss: 0.6828 - val_acc: 0.5300\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6703 - acc: 0.5841 - val_loss: 0.6669 - val_acc: 0.5825\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.6594 - acc: 0.5959 - val_loss: 0.6556 - val_acc: 0.6175\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6377 - acc: 0.6484 - val_loss: 0.6389 - val_acc: 0.6325\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6139 - acc: 0.6710 - val_loss: 0.6356 - val_acc: 0.6600\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6468 - acc: 0.6313 - val_loss: 0.6465 - val_acc: 0.6325\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6386 - acc: 0.6292 - val_loss: 0.6361 - val_acc: 0.6775\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6235 - acc: 0.6720 - val_loss: 0.6038 - val_acc: 0.6800\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5903 - acc: 0.6924 - val_loss: 0.5857 - val_acc: 0.7025\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5758 - acc: 0.7020 - val_loss: 0.5778 - val_acc: 0.7050\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5575 - acc: 0.7192 - val_loss: 0.5756 - val_acc: 0.6975\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5371 - acc: 0.7395 - val_loss: 0.5610 - val_acc: 0.7200\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5194 - acc: 0.7588 - val_loss: 0.5528 - val_acc: 0.7050\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4936 - acc: 0.7642 - val_loss: 0.5518 - val_acc: 0.7125\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4865 - acc: 0.7738 - val_loss: 0.5612 - val_acc: 0.7175\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4657 - acc: 0.7856 - val_loss: 0.6147 - val_acc: 0.6775\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4703 - acc: 0.7771 - val_loss: 0.6319 - val_acc: 0.6725\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4076 - acc: 0.8274 - val_loss: 0.6138 - val_acc: 0.7200\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3772 - acc: 0.8403 - val_loss: 0.6744 - val_acc: 0.6800\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4846 - acc: 0.7824 - val_loss: 0.7044 - val_acc: 0.6050\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5017 - acc: 0.7631 - val_loss: 0.7160 - val_acc: 0.5925\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4373 - acc: 0.8006 - val_loss: 0.7351 - val_acc: 0.6225\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4066 - acc: 0.8242 - val_loss: 0.6600 - val_acc: 0.6700\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.6756 - acc: 0.6762\n",
            "Score for fold 2: loss of 0.6755897402763367; acc of 67.61619448661804%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.7009 - acc: 0.5316 - val_loss: 0.6866 - val_acc: 0.6160\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.7019 - acc: 0.4984 - val_loss: 0.6875 - val_acc: 0.6135\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6914 - acc: 0.5209 - val_loss: 0.6860 - val_acc: 0.5112\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6818 - acc: 0.5648 - val_loss: 0.6796 - val_acc: 0.5561\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6729 - acc: 0.5798 - val_loss: 0.6640 - val_acc: 0.5910\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6530 - acc: 0.6045 - val_loss: 0.6598 - val_acc: 0.6284\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6519 - acc: 0.6238 - val_loss: 0.6484 - val_acc: 0.6284\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6478 - acc: 0.6152 - val_loss: 0.6562 - val_acc: 0.6085\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6398 - acc: 0.6238 - val_loss: 0.6342 - val_acc: 0.6459\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6180 - acc: 0.6656 - val_loss: 0.6133 - val_acc: 0.6608\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6071 - acc: 0.6613 - val_loss: 0.5885 - val_acc: 0.6908\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5674 - acc: 0.7106 - val_loss: 0.5789 - val_acc: 0.6958\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5549 - acc: 0.7224 - val_loss: 0.6186 - val_acc: 0.6908\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5520 - acc: 0.7278 - val_loss: 0.5777 - val_acc: 0.6908\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5153 - acc: 0.7449 - val_loss: 0.5736 - val_acc: 0.6933\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5093 - acc: 0.7460 - val_loss: 0.5947 - val_acc: 0.6608\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5093 - acc: 0.7417 - val_loss: 0.6205 - val_acc: 0.6658\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4573 - acc: 0.7856 - val_loss: 0.6548 - val_acc: 0.6733\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4335 - acc: 0.7996 - val_loss: 0.6518 - val_acc: 0.6658\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4232 - acc: 0.8103 - val_loss: 0.6532 - val_acc: 0.6334\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3911 - acc: 0.8307 - val_loss: 0.6584 - val_acc: 0.6933\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3501 - acc: 0.8435 - val_loss: 0.7044 - val_acc: 0.6534\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3061 - acc: 0.8778 - val_loss: 0.7788 - val_acc: 0.6284\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3122 - acc: 0.8671 - val_loss: 0.8246 - val_acc: 0.6409\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.2303 - acc: 0.9078 - val_loss: 0.9399 - val_acc: 0.6334\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.8903 - acc: 0.6502\n",
            "Score for fold 3: loss of 0.890264093875885; acc of 65.01501798629761%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.7250 - acc: 0.5048 - val_loss: 0.6963 - val_acc: 0.5100\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6974 - acc: 0.4898 - val_loss: 0.6921 - val_acc: 0.4850\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6959 - acc: 0.5380 - val_loss: 0.6979 - val_acc: 0.4900\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6937 - acc: 0.5188 - val_loss: 0.6889 - val_acc: 0.5450\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6849 - acc: 0.5648 - val_loss: 0.6860 - val_acc: 0.5575\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6754 - acc: 0.5852 - val_loss: 0.6781 - val_acc: 0.5625\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6509 - acc: 0.6345 - val_loss: 0.6617 - val_acc: 0.6050\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6834 - acc: 0.6206 - val_loss: 0.6551 - val_acc: 0.6175\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6404 - acc: 0.6688 - val_loss: 0.6615 - val_acc: 0.5950\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6410 - acc: 0.6495 - val_loss: 0.6696 - val_acc: 0.5925\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6367 - acc: 0.6559 - val_loss: 0.6558 - val_acc: 0.6200\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6207 - acc: 0.6892 - val_loss: 0.6442 - val_acc: 0.6300\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6013 - acc: 0.6806 - val_loss: 0.6339 - val_acc: 0.6275\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5853 - acc: 0.7010 - val_loss: 0.6131 - val_acc: 0.6625\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5768 - acc: 0.6999 - val_loss: 0.6113 - val_acc: 0.6900\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5779 - acc: 0.6977 - val_loss: 0.6310 - val_acc: 0.6575\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5685 - acc: 0.7170 - val_loss: 0.5987 - val_acc: 0.6475\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5452 - acc: 0.7310 - val_loss: 0.6334 - val_acc: 0.6800\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5770 - acc: 0.6967 - val_loss: 0.6053 - val_acc: 0.6800\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5493 - acc: 0.7299 - val_loss: 0.6147 - val_acc: 0.6550\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5512 - acc: 0.7353 - val_loss: 0.6153 - val_acc: 0.6625\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5202 - acc: 0.7438 - val_loss: 0.6347 - val_acc: 0.6700\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5066 - acc: 0.7578 - val_loss: 0.6331 - val_acc: 0.6800\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5024 - acc: 0.7524 - val_loss: 0.6278 - val_acc: 0.6625\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4831 - acc: 0.7889 - val_loss: 0.6428 - val_acc: 0.6750\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.6407 - acc: 0.6672\n",
            "Score for fold 4: loss of 0.640683114528656; acc of 66.71664118766785%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.7010 - acc: 0.5027 - val_loss: 0.6867 - val_acc: 0.6075\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6827 - acc: 0.5927 - val_loss: 0.6799 - val_acc: 0.6125\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6665 - acc: 0.6141 - val_loss: 0.6622 - val_acc: 0.6250\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6525 - acc: 0.6259 - val_loss: 0.6494 - val_acc: 0.6225\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6304 - acc: 0.6399 - val_loss: 0.6509 - val_acc: 0.6175\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6060 - acc: 0.6710 - val_loss: 0.6395 - val_acc: 0.6550\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6066 - acc: 0.6581 - val_loss: 0.6579 - val_acc: 0.5850\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6049 - acc: 0.6688 - val_loss: 0.6058 - val_acc: 0.6925\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5548 - acc: 0.7374 - val_loss: 0.5768 - val_acc: 0.7125\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5338 - acc: 0.7267 - val_loss: 0.5680 - val_acc: 0.7050\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5644 - acc: 0.6999 - val_loss: 0.6200 - val_acc: 0.6550\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5950 - acc: 0.6699 - val_loss: 0.6079 - val_acc: 0.6700\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5545 - acc: 0.7063 - val_loss: 0.5869 - val_acc: 0.6800\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5784 - acc: 0.7149 - val_loss: 0.6553 - val_acc: 0.6700\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6278 - acc: 0.6431 - val_loss: 0.6293 - val_acc: 0.6375\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5709 - acc: 0.7042 - val_loss: 0.6288 - val_acc: 0.6600\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5431 - acc: 0.7278 - val_loss: 0.5873 - val_acc: 0.6975\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5222 - acc: 0.7460 - val_loss: 0.5814 - val_acc: 0.6925\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4973 - acc: 0.7599 - val_loss: 0.6639 - val_acc: 0.6325\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4917 - acc: 0.7685 - val_loss: 0.5906 - val_acc: 0.7000\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4806 - acc: 0.7674 - val_loss: 0.5880 - val_acc: 0.6925\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4401 - acc: 0.8124 - val_loss: 0.6544 - val_acc: 0.6775\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4190 - acc: 0.8114 - val_loss: 0.6212 - val_acc: 0.6950\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3810 - acc: 0.8339 - val_loss: 0.6475 - val_acc: 0.6975\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3455 - acc: 0.8650 - val_loss: 0.6394 - val_acc: 0.7225\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7286 - acc: 0.6582\n",
            "Score for fold 5: loss of 0.7285758256912231; acc of 65.81709384918213%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.7366 - acc: 0.5059 - val_loss: 0.6988 - val_acc: 0.5187\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6973 - acc: 0.5113 - val_loss: 0.6951 - val_acc: 0.4888\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6886 - acc: 0.5541 - val_loss: 0.6836 - val_acc: 0.5860\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6834 - acc: 0.5488 - val_loss: 0.6799 - val_acc: 0.5686\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6705 - acc: 0.5895 - val_loss: 0.6625 - val_acc: 0.6185\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6537 - acc: 0.6217 - val_loss: 0.6350 - val_acc: 0.6284\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6386 - acc: 0.6506 - val_loss: 0.6162 - val_acc: 0.6509\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5970 - acc: 0.6838 - val_loss: 0.6254 - val_acc: 0.6284\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6007 - acc: 0.6731 - val_loss: 0.5963 - val_acc: 0.6958\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5874 - acc: 0.7031 - val_loss: 0.5735 - val_acc: 0.7157\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5635 - acc: 0.7053 - val_loss: 0.5865 - val_acc: 0.6983\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5408 - acc: 0.7395 - val_loss: 0.6113 - val_acc: 0.6559\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5512 - acc: 0.7170 - val_loss: 0.5861 - val_acc: 0.6908\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5201 - acc: 0.7621 - val_loss: 0.5581 - val_acc: 0.7307\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5144 - acc: 0.7535 - val_loss: 0.5639 - val_acc: 0.7132\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5147 - acc: 0.7524 - val_loss: 0.6421 - val_acc: 0.6534\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5006 - acc: 0.7524 - val_loss: 0.5671 - val_acc: 0.7057\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4854 - acc: 0.7653 - val_loss: 0.5575 - val_acc: 0.7157\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4684 - acc: 0.7824 - val_loss: 0.6280 - val_acc: 0.6658\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4903 - acc: 0.7738 - val_loss: 0.5522 - val_acc: 0.7132\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4366 - acc: 0.8028 - val_loss: 0.5628 - val_acc: 0.7406\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4074 - acc: 0.8274 - val_loss: 0.5762 - val_acc: 0.7207\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3837 - acc: 0.8371 - val_loss: 0.5958 - val_acc: 0.7406\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3774 - acc: 0.8328 - val_loss: 0.5901 - val_acc: 0.7257\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3840 - acc: 0.8274 - val_loss: 0.6364 - val_acc: 0.6958\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.6791 - acc: 0.6682\n",
            "Score for fold 6: loss of 0.6790756583213806; acc of 66.81681871414185%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 269ms/step - loss: 0.7145 - acc: 0.5005 - val_loss: 0.7303 - val_acc: 0.4675\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.7013 - acc: 0.5295 - val_loss: 0.6894 - val_acc: 0.5325\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6934 - acc: 0.5220 - val_loss: 0.6882 - val_acc: 0.5775\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6893 - acc: 0.5531 - val_loss: 0.6911 - val_acc: 0.4850\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6809 - acc: 0.5638 - val_loss: 0.6757 - val_acc: 0.6175\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6698 - acc: 0.6109 - val_loss: 0.6529 - val_acc: 0.6275\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6490 - acc: 0.6324 - val_loss: 0.6091 - val_acc: 0.6725\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6488 - acc: 0.6388 - val_loss: 0.6719 - val_acc: 0.5725\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6495 - acc: 0.6066 - val_loss: 0.6374 - val_acc: 0.6475\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6255 - acc: 0.6677 - val_loss: 0.6110 - val_acc: 0.6775\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6066 - acc: 0.6860 - val_loss: 0.5953 - val_acc: 0.6875\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6063 - acc: 0.6902 - val_loss: 0.5904 - val_acc: 0.6950\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5984 - acc: 0.6752 - val_loss: 0.5968 - val_acc: 0.6975\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5929 - acc: 0.6892 - val_loss: 0.5914 - val_acc: 0.6925\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5723 - acc: 0.7128 - val_loss: 0.5854 - val_acc: 0.6975\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5612 - acc: 0.7192 - val_loss: 0.5413 - val_acc: 0.7350\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5353 - acc: 0.7363 - val_loss: 0.5307 - val_acc: 0.7400\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5217 - acc: 0.7503 - val_loss: 0.5205 - val_acc: 0.7400\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4930 - acc: 0.7696 - val_loss: 0.5303 - val_acc: 0.7400\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5281 - acc: 0.7438 - val_loss: 0.6178 - val_acc: 0.6700\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5472 - acc: 0.7235 - val_loss: 0.7041 - val_acc: 0.5975\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5315 - acc: 0.7245 - val_loss: 0.5934 - val_acc: 0.6850\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4914 - acc: 0.7738 - val_loss: 0.7658 - val_acc: 0.6525\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4900 - acc: 0.7803 - val_loss: 0.5960 - val_acc: 0.7075\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4452 - acc: 0.7910 - val_loss: 0.6161 - val_acc: 0.6750\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.6789 - acc: 0.6717\n",
            "Score for fold 7: loss of 0.6789422035217285; acc of 67.16641783714294%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 272ms/step - loss: 0.7256 - acc: 0.4737 - val_loss: 0.6910 - val_acc: 0.5225\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6914 - acc: 0.5209 - val_loss: 0.6854 - val_acc: 0.5625\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6822 - acc: 0.5477 - val_loss: 0.6790 - val_acc: 0.6200\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6650 - acc: 0.6292 - val_loss: 0.6737 - val_acc: 0.5675\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6511 - acc: 0.6056 - val_loss: 0.6548 - val_acc: 0.6250\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6434 - acc: 0.6163 - val_loss: 0.6462 - val_acc: 0.6250\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6260 - acc: 0.6452 - val_loss: 0.6485 - val_acc: 0.6300\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6192 - acc: 0.6710 - val_loss: 0.6413 - val_acc: 0.6675\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6053 - acc: 0.6785 - val_loss: 0.6336 - val_acc: 0.6875\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5637 - acc: 0.7170 - val_loss: 0.6118 - val_acc: 0.7000\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5692 - acc: 0.7010 - val_loss: 0.5794 - val_acc: 0.7025\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5483 - acc: 0.7320 - val_loss: 0.5932 - val_acc: 0.7125\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5384 - acc: 0.7256 - val_loss: 0.5995 - val_acc: 0.6925\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5517 - acc: 0.7074 - val_loss: 0.6346 - val_acc: 0.6475\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5603 - acc: 0.7010 - val_loss: 0.6140 - val_acc: 0.6600\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5283 - acc: 0.7374 - val_loss: 0.5769 - val_acc: 0.7025\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5068 - acc: 0.7556 - val_loss: 0.5858 - val_acc: 0.7100\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4684 - acc: 0.7771 - val_loss: 0.6073 - val_acc: 0.6925\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4616 - acc: 0.7824 - val_loss: 0.5871 - val_acc: 0.7025\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4355 - acc: 0.7931 - val_loss: 0.6148 - val_acc: 0.6975\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4472 - acc: 0.8039 - val_loss: 0.6392 - val_acc: 0.6575\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4457 - acc: 0.7921 - val_loss: 0.6120 - val_acc: 0.7000\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3740 - acc: 0.8478 - val_loss: 0.6830 - val_acc: 0.7075\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3766 - acc: 0.8371 - val_loss: 0.6354 - val_acc: 0.7150\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3412 - acc: 0.8617 - val_loss: 0.7313 - val_acc: 0.7075\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.8159 - acc: 0.6312\n",
            "Score for fold 8: loss of 0.8159184455871582; acc of 63.11843991279602%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7066 - acc: 0.5005 - val_loss: 0.6916 - val_acc: 0.5237\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6967 - acc: 0.5038 - val_loss: 0.6947 - val_acc: 0.4788\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6904 - acc: 0.5102 - val_loss: 0.6865 - val_acc: 0.5486\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6813 - acc: 0.5916 - val_loss: 0.6877 - val_acc: 0.5387\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6711 - acc: 0.5938 - val_loss: 0.6672 - val_acc: 0.6010\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6356 - acc: 0.6474 - val_loss: 0.6551 - val_acc: 0.6185\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6876 - acc: 0.6302 - val_loss: 0.6628 - val_acc: 0.6209\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6903 - acc: 0.5606 - val_loss: 0.6711 - val_acc: 0.6085\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6676 - acc: 0.5991 - val_loss: 0.6866 - val_acc: 0.5137\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6706 - acc: 0.5595 - val_loss: 0.6846 - val_acc: 0.5312\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6643 - acc: 0.6152 - val_loss: 0.6718 - val_acc: 0.5960\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6539 - acc: 0.6399 - val_loss: 0.6596 - val_acc: 0.6135\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6381 - acc: 0.6517 - val_loss: 0.6544 - val_acc: 0.6234\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6193 - acc: 0.6688 - val_loss: 0.6289 - val_acc: 0.6608\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6076 - acc: 0.6742 - val_loss: 0.6198 - val_acc: 0.6783\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6121 - acc: 0.6752 - val_loss: 0.5970 - val_acc: 0.6908\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5614 - acc: 0.7117 - val_loss: 0.6403 - val_acc: 0.6284\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5732 - acc: 0.7063 - val_loss: 0.6069 - val_acc: 0.6808\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5672 - acc: 0.7245 - val_loss: 0.6107 - val_acc: 0.6708\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5456 - acc: 0.7342 - val_loss: 0.6641 - val_acc: 0.6608\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5318 - acc: 0.7395 - val_loss: 0.5847 - val_acc: 0.6958\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5297 - acc: 0.7395 - val_loss: 0.6001 - val_acc: 0.7007\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5425 - acc: 0.7278 - val_loss: 0.5923 - val_acc: 0.6858\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5035 - acc: 0.7685 - val_loss: 0.6341 - val_acc: 0.6484\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5174 - acc: 0.7621 - val_loss: 0.5914 - val_acc: 0.7157\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.6008 - acc: 0.6967\n",
            "Score for fold 9: loss of 0.6007794737815857; acc of 69.66966986656189%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.7050 - acc: 0.5348 - val_loss: 0.6920 - val_acc: 0.5250\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6902 - acc: 0.5477 - val_loss: 0.7091 - val_acc: 0.4775\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6882 - acc: 0.5359 - val_loss: 0.6841 - val_acc: 0.5550\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6752 - acc: 0.5681 - val_loss: 0.6816 - val_acc: 0.5550\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6545 - acc: 0.6388 - val_loss: 0.7196 - val_acc: 0.5350\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6525 - acc: 0.6259 - val_loss: 0.7497 - val_acc: 0.5225\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6387 - acc: 0.6463 - val_loss: 0.6647 - val_acc: 0.6050\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6378 - acc: 0.6399 - val_loss: 0.7222 - val_acc: 0.5250\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6392 - acc: 0.6120 - val_loss: 0.6440 - val_acc: 0.6225\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6023 - acc: 0.6935 - val_loss: 0.8166 - val_acc: 0.5600\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6363 - acc: 0.6667 - val_loss: 0.6372 - val_acc: 0.6150\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5999 - acc: 0.6892 - val_loss: 0.6839 - val_acc: 0.5775\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5868 - acc: 0.7031 - val_loss: 0.6261 - val_acc: 0.6575\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5667 - acc: 0.7149 - val_loss: 0.6488 - val_acc: 0.6725\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5986 - acc: 0.6913 - val_loss: 0.6333 - val_acc: 0.6375\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5680 - acc: 0.7063 - val_loss: 0.6287 - val_acc: 0.6300\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5480 - acc: 0.7353 - val_loss: 0.6655 - val_acc: 0.6025\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5252 - acc: 0.7524 - val_loss: 0.6290 - val_acc: 0.6600\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5087 - acc: 0.7588 - val_loss: 0.6287 - val_acc: 0.6525\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4845 - acc: 0.7717 - val_loss: 0.7009 - val_acc: 0.6175\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4595 - acc: 0.7814 - val_loss: 0.7076 - val_acc: 0.6400\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4271 - acc: 0.8135 - val_loss: 0.7442 - val_acc: 0.6225\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3826 - acc: 0.8414 - val_loss: 0.7007 - val_acc: 0.6575\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3508 - acc: 0.8510 - val_loss: 0.8348 - val_acc: 0.5900\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3392 - acc: 0.8510 - val_loss: 0.7934 - val_acc: 0.6400\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.6718 - acc: 0.6972\n",
            "Score for fold 10: loss of 0.6717891097068787; acc of 69.71514225006104%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 270ms/step - loss: 0.7080 - acc: 0.4952 - val_loss: 0.6881 - val_acc: 0.5300\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6883 - acc: 0.5380 - val_loss: 0.6844 - val_acc: 0.5725\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6809 - acc: 0.5659 - val_loss: 0.6865 - val_acc: 0.5175\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6642 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6225\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6447 - acc: 0.6292 - val_loss: 0.6441 - val_acc: 0.6275\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6499 - acc: 0.6420 - val_loss: 0.6781 - val_acc: 0.6025\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6502 - acc: 0.6302 - val_loss: 0.6623 - val_acc: 0.5725\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6423 - acc: 0.6238 - val_loss: 0.6622 - val_acc: 0.5725\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6240 - acc: 0.6774 - val_loss: 0.6315 - val_acc: 0.6575\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6017 - acc: 0.6785 - val_loss: 0.6539 - val_acc: 0.6175\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5833 - acc: 0.6860 - val_loss: 0.7375 - val_acc: 0.6300\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5772 - acc: 0.6913 - val_loss: 0.5879 - val_acc: 0.6825\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5395 - acc: 0.7438 - val_loss: 0.5764 - val_acc: 0.7025\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5313 - acc: 0.7385 - val_loss: 0.5722 - val_acc: 0.7000\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5360 - acc: 0.7417 - val_loss: 0.5994 - val_acc: 0.6825\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5000 - acc: 0.7588 - val_loss: 0.6371 - val_acc: 0.6850\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5048 - acc: 0.7567 - val_loss: 0.5881 - val_acc: 0.7025\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4684 - acc: 0.7749 - val_loss: 0.5899 - val_acc: 0.7025\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4259 - acc: 0.8092 - val_loss: 0.6148 - val_acc: 0.7150\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4068 - acc: 0.8232 - val_loss: 0.6128 - val_acc: 0.6850\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4269 - acc: 0.8039 - val_loss: 0.5920 - val_acc: 0.7125\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4182 - acc: 0.8103 - val_loss: 0.7526 - val_acc: 0.6250\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3724 - acc: 0.8392 - val_loss: 0.7378 - val_acc: 0.6900\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3572 - acc: 0.8478 - val_loss: 0.6663 - val_acc: 0.6825\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3033 - acc: 0.8596 - val_loss: 0.7923 - val_acc: 0.7000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7913 - acc: 0.6987\n",
            "Score for fold 11: loss of 0.7912672758102417; acc of 69.86506581306458%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.7513 - acc: 0.4802 - val_loss: 0.7070 - val_acc: 0.4938\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6967 - acc: 0.5155 - val_loss: 0.6897 - val_acc: 0.5037\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6862 - acc: 0.5488 - val_loss: 0.6861 - val_acc: 0.5910\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6781 - acc: 0.6045 - val_loss: 0.6793 - val_acc: 0.6010\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6675 - acc: 0.5916 - val_loss: 0.6550 - val_acc: 0.6135\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6481 - acc: 0.6270 - val_loss: 0.6250 - val_acc: 0.6584\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6291 - acc: 0.6409 - val_loss: 0.6225 - val_acc: 0.6633\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6096 - acc: 0.6763 - val_loss: 0.5985 - val_acc: 0.6783\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6071 - acc: 0.6720 - val_loss: 0.5655 - val_acc: 0.7307\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6030 - acc: 0.6785 - val_loss: 0.6726 - val_acc: 0.5686\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6381 - acc: 0.6184 - val_loss: 0.6369 - val_acc: 0.6284\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6296 - acc: 0.6602 - val_loss: 0.6403 - val_acc: 0.6209\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6059 - acc: 0.7020 - val_loss: 0.6168 - val_acc: 0.6608\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5782 - acc: 0.6956 - val_loss: 0.5949 - val_acc: 0.6783\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5688 - acc: 0.7224 - val_loss: 0.6128 - val_acc: 0.6833\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5658 - acc: 0.7095 - val_loss: 0.5877 - val_acc: 0.7157\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5462 - acc: 0.7224 - val_loss: 0.5744 - val_acc: 0.6908\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5210 - acc: 0.7578 - val_loss: 0.5517 - val_acc: 0.7257\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5317 - acc: 0.7235 - val_loss: 0.5660 - val_acc: 0.7406\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5036 - acc: 0.7653 - val_loss: 0.5644 - val_acc: 0.7182\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4982 - acc: 0.7631 - val_loss: 0.5663 - val_acc: 0.7057\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4892 - acc: 0.7728 - val_loss: 0.5570 - val_acc: 0.7107\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4667 - acc: 0.7964 - val_loss: 0.5657 - val_acc: 0.7082\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4644 - acc: 0.7814 - val_loss: 0.5853 - val_acc: 0.7057\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4554 - acc: 0.7878 - val_loss: 0.5772 - val_acc: 0.7082\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.5915 - acc: 0.7027\n",
            "Score for fold 12: loss of 0.5914857387542725; acc of 70.27027010917664%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7395 - acc: 0.4973 - val_loss: 0.7109 - val_acc: 0.4825\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6961 - acc: 0.5091 - val_loss: 0.6882 - val_acc: 0.5600\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6830 - acc: 0.5766 - val_loss: 0.6893 - val_acc: 0.5025\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6703 - acc: 0.5874 - val_loss: 0.6726 - val_acc: 0.6075\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6572 - acc: 0.6313 - val_loss: 0.6688 - val_acc: 0.6075\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6668 - acc: 0.6024 - val_loss: 0.6552 - val_acc: 0.6475\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6862 - acc: 0.5627 - val_loss: 0.6671 - val_acc: 0.5950\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6547 - acc: 0.5981 - val_loss: 0.7032 - val_acc: 0.4950\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6591 - acc: 0.5788 - val_loss: 0.6713 - val_acc: 0.5900\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6484 - acc: 0.6538 - val_loss: 0.6592 - val_acc: 0.6075\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6244 - acc: 0.6602 - val_loss: 0.6793 - val_acc: 0.6000\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6103 - acc: 0.6688 - val_loss: 0.6317 - val_acc: 0.6550\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5827 - acc: 0.6967 - val_loss: 0.5924 - val_acc: 0.7125\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5645 - acc: 0.7170 - val_loss: 0.5968 - val_acc: 0.6850\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5544 - acc: 0.7245 - val_loss: 0.5733 - val_acc: 0.7000\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5121 - acc: 0.7524 - val_loss: 0.5798 - val_acc: 0.7050\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5478 - acc: 0.7353 - val_loss: 0.6559 - val_acc: 0.6075\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5329 - acc: 0.7460 - val_loss: 0.6037 - val_acc: 0.6775\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5029 - acc: 0.7621 - val_loss: 0.6057 - val_acc: 0.7000\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4878 - acc: 0.7546 - val_loss: 0.6102 - val_acc: 0.6950\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4534 - acc: 0.8028 - val_loss: 0.6623 - val_acc: 0.6750\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4243 - acc: 0.8114 - val_loss: 0.7033 - val_acc: 0.6500\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4039 - acc: 0.8253 - val_loss: 0.6544 - val_acc: 0.6800\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4022 - acc: 0.8232 - val_loss: 0.8293 - val_acc: 0.6100\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4029 - acc: 0.8167 - val_loss: 0.7470 - val_acc: 0.6275\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7063 - acc: 0.6507\n",
            "Score for fold 13: loss of 0.7062950134277344; acc of 65.06746411323547%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.7100 - acc: 0.5016 - val_loss: 0.6870 - val_acc: 0.5075\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6966 - acc: 0.4973 - val_loss: 0.6840 - val_acc: 0.5875\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6910 - acc: 0.5380 - val_loss: 0.6807 - val_acc: 0.5775\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6757 - acc: 0.6077 - val_loss: 0.6724 - val_acc: 0.5875\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6662 - acc: 0.6099 - val_loss: 0.6491 - val_acc: 0.6525\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6421 - acc: 0.6324 - val_loss: 0.6085 - val_acc: 0.6950\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6485 - acc: 0.6377 - val_loss: 0.6224 - val_acc: 0.6625\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6184 - acc: 0.6538 - val_loss: 0.6445 - val_acc: 0.6175\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6138 - acc: 0.6870 - val_loss: 0.6353 - val_acc: 0.6200\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6111 - acc: 0.6742 - val_loss: 0.6287 - val_acc: 0.6525\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5949 - acc: 0.6817 - val_loss: 0.6533 - val_acc: 0.6225\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6153 - acc: 0.6559 - val_loss: 0.5767 - val_acc: 0.6975\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5652 - acc: 0.7235 - val_loss: 0.5655 - val_acc: 0.7000\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5256 - acc: 0.7503 - val_loss: 0.5340 - val_acc: 0.7375\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5248 - acc: 0.7449 - val_loss: 0.5873 - val_acc: 0.6725\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5282 - acc: 0.7492 - val_loss: 0.5378 - val_acc: 0.7300\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4811 - acc: 0.7696 - val_loss: 0.6470 - val_acc: 0.6925\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5367 - acc: 0.7428 - val_loss: 0.6130 - val_acc: 0.6375\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5257 - acc: 0.7406 - val_loss: 0.6126 - val_acc: 0.6850\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5096 - acc: 0.7503 - val_loss: 0.5895 - val_acc: 0.6850\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4767 - acc: 0.7728 - val_loss: 0.5627 - val_acc: 0.7100\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4406 - acc: 0.8081 - val_loss: 0.6046 - val_acc: 0.7100\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4070 - acc: 0.8274 - val_loss: 0.6187 - val_acc: 0.7200\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3753 - acc: 0.8382 - val_loss: 0.6200 - val_acc: 0.6900\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3453 - acc: 0.8617 - val_loss: 0.7393 - val_acc: 0.6850\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7982 - acc: 0.6462\n",
            "Score for fold 14: loss of 0.798221230506897; acc of 64.61769342422485%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 265ms/step - loss: 0.7348 - acc: 0.4780 - val_loss: 0.6912 - val_acc: 0.5237\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6931 - acc: 0.5155 - val_loss: 0.6909 - val_acc: 0.4813\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6851 - acc: 0.5413 - val_loss: 0.6840 - val_acc: 0.5810\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.6755 - acc: 0.6206 - val_loss: 0.6725 - val_acc: 0.5885\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6505 - acc: 0.6324 - val_loss: 0.6511 - val_acc: 0.6209\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6166 - acc: 0.6667 - val_loss: 0.6595 - val_acc: 0.6359\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6020 - acc: 0.6677 - val_loss: 0.6195 - val_acc: 0.6434\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5857 - acc: 0.7010 - val_loss: 0.5980 - val_acc: 0.6833\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5672 - acc: 0.7106 - val_loss: 0.5869 - val_acc: 0.6883\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5374 - acc: 0.7503 - val_loss: 0.5864 - val_acc: 0.7032\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5649 - acc: 0.7042 - val_loss: 0.5736 - val_acc: 0.6908\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5154 - acc: 0.7599 - val_loss: 0.5781 - val_acc: 0.7107\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5280 - acc: 0.7524 - val_loss: 0.5971 - val_acc: 0.6833\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5428 - acc: 0.6999 - val_loss: 0.6186 - val_acc: 0.6633\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5371 - acc: 0.7460 - val_loss: 0.5840 - val_acc: 0.6958\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5004 - acc: 0.7706 - val_loss: 0.5970 - val_acc: 0.6883\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4686 - acc: 0.7856 - val_loss: 0.7252 - val_acc: 0.6683\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5276 - acc: 0.7278 - val_loss: 0.6501 - val_acc: 0.6534\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4822 - acc: 0.7599 - val_loss: 0.5623 - val_acc: 0.7032\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4283 - acc: 0.8124 - val_loss: 0.5760 - val_acc: 0.7182\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4066 - acc: 0.8135 - val_loss: 0.5885 - val_acc: 0.7107\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4280 - acc: 0.8081 - val_loss: 0.6381 - val_acc: 0.6633\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4049 - acc: 0.8328 - val_loss: 0.5938 - val_acc: 0.7082\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3549 - acc: 0.8639 - val_loss: 0.6234 - val_acc: 0.6933\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3023 - acc: 0.8800 - val_loss: 0.6788 - val_acc: 0.6908\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.8213 - acc: 0.6667\n",
            "Score for fold 15: loss of 0.8213199377059937; acc of 66.66666865348816%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 266ms/step - loss: 0.7143 - acc: 0.5145 - val_loss: 0.7020 - val_acc: 0.4850\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6995 - acc: 0.5134 - val_loss: 0.6858 - val_acc: 0.5775\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6887 - acc: 0.5338 - val_loss: 0.6795 - val_acc: 0.5725\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6734 - acc: 0.5938 - val_loss: 0.6702 - val_acc: 0.5850\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6628 - acc: 0.6174 - val_loss: 0.6735 - val_acc: 0.5825\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6519 - acc: 0.6217 - val_loss: 0.6427 - val_acc: 0.6375\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6253 - acc: 0.6527 - val_loss: 0.7040 - val_acc: 0.5925\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6227 - acc: 0.6517 - val_loss: 0.6256 - val_acc: 0.6375\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6085 - acc: 0.6645 - val_loss: 0.5979 - val_acc: 0.6700\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5763 - acc: 0.7085 - val_loss: 0.6009 - val_acc: 0.6825\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5773 - acc: 0.6902 - val_loss: 0.6340 - val_acc: 0.6275\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5662 - acc: 0.7170 - val_loss: 0.5755 - val_acc: 0.7025\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5275 - acc: 0.7546 - val_loss: 0.6272 - val_acc: 0.6700\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5641 - acc: 0.7117 - val_loss: 0.5767 - val_acc: 0.6925\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5600 - acc: 0.7095 - val_loss: 0.5955 - val_acc: 0.6750\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5311 - acc: 0.7503 - val_loss: 0.5728 - val_acc: 0.6950\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4873 - acc: 0.7663 - val_loss: 0.5764 - val_acc: 0.7225\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4755 - acc: 0.7803 - val_loss: 0.5808 - val_acc: 0.6875\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4470 - acc: 0.7964 - val_loss: 0.5356 - val_acc: 0.7400\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4360 - acc: 0.7974 - val_loss: 0.7321 - val_acc: 0.6700\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4682 - acc: 0.7856 - val_loss: 0.6404 - val_acc: 0.6725\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4321 - acc: 0.8049 - val_loss: 0.6701 - val_acc: 0.6725\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4015 - acc: 0.8285 - val_loss: 0.7223 - val_acc: 0.6450\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3994 - acc: 0.8199 - val_loss: 0.6012 - val_acc: 0.7200\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3665 - acc: 0.8446 - val_loss: 0.6401 - val_acc: 0.6925\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7098 - acc: 0.6762\n",
            "Score for fold 16: loss of 0.7098388075828552; acc of 67.61619448661804%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 277ms/step - loss: 0.7389 - acc: 0.4920 - val_loss: 0.7144 - val_acc: 0.5025\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.7128 - acc: 0.5230 - val_loss: 0.6913 - val_acc: 0.5125\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6941 - acc: 0.5177 - val_loss: 0.6941 - val_acc: 0.5000\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6921 - acc: 0.5123 - val_loss: 0.6913 - val_acc: 0.5050\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6899 - acc: 0.5209 - val_loss: 0.6912 - val_acc: 0.5025\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6850 - acc: 0.5370 - val_loss: 0.6850 - val_acc: 0.5975\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6794 - acc: 0.5766 - val_loss: 0.6768 - val_acc: 0.5775\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6657 - acc: 0.5970 - val_loss: 0.6554 - val_acc: 0.6425\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6589 - acc: 0.6324 - val_loss: 0.7507 - val_acc: 0.5475\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6872 - acc: 0.5938 - val_loss: 0.6545 - val_acc: 0.6325\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6593 - acc: 0.6045 - val_loss: 0.6796 - val_acc: 0.5350\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6655 - acc: 0.5820 - val_loss: 0.6703 - val_acc: 0.6175\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6575 - acc: 0.6399 - val_loss: 0.6640 - val_acc: 0.6300\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6495 - acc: 0.6495 - val_loss: 0.6536 - val_acc: 0.6350\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6408 - acc: 0.6292 - val_loss: 0.6475 - val_acc: 0.6225\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6194 - acc: 0.6624 - val_loss: 0.6343 - val_acc: 0.6375\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6071 - acc: 0.6667 - val_loss: 0.6601 - val_acc: 0.6300\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6022 - acc: 0.6806 - val_loss: 0.6089 - val_acc: 0.6650\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5759 - acc: 0.7063 - val_loss: 0.6349 - val_acc: 0.6800\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5658 - acc: 0.7170 - val_loss: 0.5932 - val_acc: 0.6950\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5684 - acc: 0.7160 - val_loss: 0.5641 - val_acc: 0.6975\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5585 - acc: 0.7181 - val_loss: 0.5680 - val_acc: 0.7025\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5323 - acc: 0.7353 - val_loss: 0.5605 - val_acc: 0.6950\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5217 - acc: 0.7438 - val_loss: 0.5468 - val_acc: 0.7175\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4958 - acc: 0.7567 - val_loss: 0.5629 - val_acc: 0.7100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.5815 - acc: 0.6957\n",
            "Score for fold 17: loss of 0.5814629197120667; acc of 69.5652186870575%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.7454 - acc: 0.4887 - val_loss: 0.7142 - val_acc: 0.5062\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6968 - acc: 0.5209 - val_loss: 0.6968 - val_acc: 0.4988\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6885 - acc: 0.5220 - val_loss: 0.6854 - val_acc: 0.5436\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6835 - acc: 0.5456 - val_loss: 0.6803 - val_acc: 0.5810\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6795 - acc: 0.5488 - val_loss: 0.6753 - val_acc: 0.5860\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6600 - acc: 0.6120 - val_loss: 0.6672 - val_acc: 0.5985\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6501 - acc: 0.6120 - val_loss: 0.6491 - val_acc: 0.5885\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6325 - acc: 0.6474 - val_loss: 0.6482 - val_acc: 0.6534\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6057 - acc: 0.6742 - val_loss: 0.6175 - val_acc: 0.6185\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5947 - acc: 0.6892 - val_loss: 0.6140 - val_acc: 0.6683\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5815 - acc: 0.6935 - val_loss: 0.6212 - val_acc: 0.6833\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5831 - acc: 0.7020 - val_loss: 0.5981 - val_acc: 0.6683\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5274 - acc: 0.7395 - val_loss: 0.5650 - val_acc: 0.7107\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5240 - acc: 0.7471 - val_loss: 0.5673 - val_acc: 0.6708\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5428 - acc: 0.7278 - val_loss: 0.5693 - val_acc: 0.6758\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5204 - acc: 0.7471 - val_loss: 0.5921 - val_acc: 0.7032\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5026 - acc: 0.7663 - val_loss: 0.5986 - val_acc: 0.7007\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4752 - acc: 0.7663 - val_loss: 0.5997 - val_acc: 0.7032\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4549 - acc: 0.7889 - val_loss: 0.6258 - val_acc: 0.6908\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4089 - acc: 0.8221 - val_loss: 0.6820 - val_acc: 0.6608\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3991 - acc: 0.8360 - val_loss: 0.6453 - val_acc: 0.7082\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3432 - acc: 0.8607 - val_loss: 0.6943 - val_acc: 0.7082\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3220 - acc: 0.8703 - val_loss: 0.7723 - val_acc: 0.6110\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3041 - acc: 0.8800 - val_loss: 0.7644 - val_acc: 0.6783\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.2692 - acc: 0.8896 - val_loss: 0.8067 - val_acc: 0.7107\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.8132 - acc: 0.6877\n",
            "Score for fold 18: loss of 0.8132135272026062; acc of 68.76876950263977%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.7289 - acc: 0.4984 - val_loss: 0.6891 - val_acc: 0.5225\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6913 - acc: 0.5348 - val_loss: 0.6981 - val_acc: 0.4775\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6762 - acc: 0.5809 - val_loss: 0.6799 - val_acc: 0.5575\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6704 - acc: 0.5766 - val_loss: 0.6909 - val_acc: 0.5225\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6520 - acc: 0.6302 - val_loss: 0.6496 - val_acc: 0.6250\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6219 - acc: 0.6570 - val_loss: 0.7058 - val_acc: 0.5925\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6699 - acc: 0.6120 - val_loss: 0.6567 - val_acc: 0.6050\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6172 - acc: 0.6495 - val_loss: 0.6527 - val_acc: 0.6000\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6098 - acc: 0.6860 - val_loss: 0.6260 - val_acc: 0.6575\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5841 - acc: 0.7042 - val_loss: 0.6539 - val_acc: 0.6475\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5633 - acc: 0.7160 - val_loss: 0.7276 - val_acc: 0.6550\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6022 - acc: 0.6752 - val_loss: 0.6413 - val_acc: 0.6475\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5688 - acc: 0.7020 - val_loss: 0.5989 - val_acc: 0.6675\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5543 - acc: 0.7256 - val_loss: 0.6095 - val_acc: 0.6775\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5152 - acc: 0.7503 - val_loss: 0.5940 - val_acc: 0.7075\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5397 - acc: 0.7331 - val_loss: 0.6433 - val_acc: 0.6800\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5247 - acc: 0.7417 - val_loss: 0.6427 - val_acc: 0.6350\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5665 - acc: 0.7042 - val_loss: 0.6695 - val_acc: 0.6125\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5235 - acc: 0.7471 - val_loss: 0.6101 - val_acc: 0.6550\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4928 - acc: 0.7696 - val_loss: 0.6392 - val_acc: 0.6800\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4631 - acc: 0.7910 - val_loss: 0.7040 - val_acc: 0.6525\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4911 - acc: 0.7653 - val_loss: 0.7294 - val_acc: 0.6175\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5145 - acc: 0.7385 - val_loss: 0.6223 - val_acc: 0.6600\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4777 - acc: 0.7717 - val_loss: 0.6756 - val_acc: 0.6600\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4225 - acc: 0.8114 - val_loss: 0.7085 - val_acc: 0.6675\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7142 - acc: 0.6462\n",
            "Score for fold 19: loss of 0.7141525745391846; acc of 64.61769342422485%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.7543 - acc: 0.5005 - val_loss: 0.7172 - val_acc: 0.5100\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.7044 - acc: 0.5080 - val_loss: 0.7018 - val_acc: 0.4900\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.7140 - acc: 0.4973 - val_loss: 0.6945 - val_acc: 0.4875\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6944 - acc: 0.5188 - val_loss: 0.6934 - val_acc: 0.5100\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6923 - acc: 0.5113 - val_loss: 0.6889 - val_acc: 0.5400\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6879 - acc: 0.5520 - val_loss: 0.6882 - val_acc: 0.5600\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6815 - acc: 0.5970 - val_loss: 0.6807 - val_acc: 0.5900\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6697 - acc: 0.6066 - val_loss: 0.6628 - val_acc: 0.6050\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6553 - acc: 0.5959 - val_loss: 0.6728 - val_acc: 0.6000\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6327 - acc: 0.6463 - val_loss: 0.7619 - val_acc: 0.5450\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6761 - acc: 0.6066 - val_loss: 0.6642 - val_acc: 0.5825\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6539 - acc: 0.5777 - val_loss: 0.6542 - val_acc: 0.6250\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6446 - acc: 0.6592 - val_loss: 0.6534 - val_acc: 0.6500\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6269 - acc: 0.6870 - val_loss: 0.6314 - val_acc: 0.6425\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5952 - acc: 0.6849 - val_loss: 0.6106 - val_acc: 0.6525\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5728 - acc: 0.7042 - val_loss: 0.6538 - val_acc: 0.6825\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6312 - acc: 0.6635 - val_loss: 0.5972 - val_acc: 0.6650\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5889 - acc: 0.6913 - val_loss: 0.6088 - val_acc: 0.6775\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5757 - acc: 0.7320 - val_loss: 0.6032 - val_acc: 0.6875\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5495 - acc: 0.7299 - val_loss: 0.5767 - val_acc: 0.6875\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5412 - acc: 0.7320 - val_loss: 0.6470 - val_acc: 0.6750\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5305 - acc: 0.7310 - val_loss: 0.5777 - val_acc: 0.6800\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5228 - acc: 0.7353 - val_loss: 0.5925 - val_acc: 0.6925\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4989 - acc: 0.7663 - val_loss: 0.5779 - val_acc: 0.6950\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4790 - acc: 0.7685 - val_loss: 0.7758 - val_acc: 0.6400\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.7507 - acc: 0.6627\n",
            "Score for fold 20: loss of 0.7506766319274902; acc of 66.26686453819275%\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 1s 285ms/step - loss: 0.7360 - acc: 0.5123 - val_loss: 0.7002 - val_acc: 0.5187\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6989 - acc: 0.5016 - val_loss: 0.7032 - val_acc: 0.4863\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6964 - acc: 0.5252 - val_loss: 0.6863 - val_acc: 0.5860\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6822 - acc: 0.5788 - val_loss: 0.6836 - val_acc: 0.5810\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6756 - acc: 0.5991 - val_loss: 0.6731 - val_acc: 0.6010\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6657 - acc: 0.6109 - val_loss: 0.7228 - val_acc: 0.5237\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6533 - acc: 0.6109 - val_loss: 0.6772 - val_acc: 0.5860\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6548 - acc: 0.6141 - val_loss: 0.6980 - val_acc: 0.5486\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6457 - acc: 0.6195 - val_loss: 0.6493 - val_acc: 0.6259\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6229 - acc: 0.6570 - val_loss: 0.6608 - val_acc: 0.5960\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5914 - acc: 0.6913 - val_loss: 0.6734 - val_acc: 0.6733\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6215 - acc: 0.6849 - val_loss: 0.7013 - val_acc: 0.5761\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6171 - acc: 0.6913 - val_loss: 0.6510 - val_acc: 0.6509\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.6357 - acc: 0.6409 - val_loss: 0.6445 - val_acc: 0.6384\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.6119 - acc: 0.6945 - val_loss: 0.6416 - val_acc: 0.6160\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.5939 - acc: 0.6977 - val_loss: 0.6187 - val_acc: 0.6534\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5549 - acc: 0.7267 - val_loss: 0.6042 - val_acc: 0.6883\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5489 - acc: 0.7095 - val_loss: 0.6389 - val_acc: 0.6608\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5341 - acc: 0.7320 - val_loss: 0.5720 - val_acc: 0.6808\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5094 - acc: 0.7578 - val_loss: 0.5888 - val_acc: 0.7107\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5331 - acc: 0.7353 - val_loss: 0.5784 - val_acc: 0.7107\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.5071 - acc: 0.7588 - val_loss: 0.6071 - val_acc: 0.6908\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4792 - acc: 0.7781 - val_loss: 0.6291 - val_acc: 0.6658\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4716 - acc: 0.7771 - val_loss: 0.5797 - val_acc: 0.7082\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4174 - acc: 0.8114 - val_loss: 0.5752 - val_acc: 0.7182\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.6204 - acc: 0.7042\n",
            "Score for fold 21: loss of 0.6203966736793518; acc of 70.42042016983032%\n",
            "Average scores for all folds:\n",
            "> Accuracy: 67.02203438395546 (+- 2.3518627286104827)\n",
            "> Loss: 0.7175502805482774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWYjv3D_ZMj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFU22PnP7rmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xl675TS_1w"
      },
      "source": [
        "# # Classifier - Algorithm - SVM\n",
        "# # fit the training dataset on the classifier\n",
        "# SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "# SVM.fit(xtraintf,ytrain)\n",
        "# # predict the labels on validation dataset\n",
        "# predictions_SVM = SVM.predict(xtesttf)\n",
        "# # Use accuracy_score function to get the accuracy\n",
        "# print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, ytest)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgsYaoKMS_1w"
      },
      "source": [
        "# count_vect = CountVectorizer(max_features=5000)\n",
        "# #count_vect.fit(df['text'])\n",
        "# xtrainc = count_vect.fit_transform(xtrain)\n",
        "# xtestc = count_vect.transform(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vls0RZ5pS_1w"
      },
      "source": [
        "# # Classifier - Algorithm - SVM\n",
        "# # fit the training dataset on the classifier\n",
        "# SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "# SVM.fit(xtrainc,ytrain)\n",
        "# # predict the labels on validation dataset\n",
        "# predictions_SVM = SVM.predict(xtestc)\n",
        "# # Use accuracy_score function to get the accuracy\n",
        "# print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, ytest)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxJmPv_pS_1w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}